
# AI Recruiter Agency ðŸ¤–

An intelligent recruitment analysis system powered by Ollama (LLaMA 3.2) and Swarm Framework that automates resume processing, candidate screening, and job matching through coordinated AI agents.
## Features âœ¨

â€¢	Intelligent Resume Analysis: Extract and analyze key       information from PDF resumes

â€¢	Skills Assessment: Comprehensive evaluation of candidate skills and experience

â€¢	Automated Job Matching: Match candidates with suitable positions based on skills and requirements

â€¢	Smart Screening: AI-powered candidate screening with detailed reporting

â€¢	Intelligent Recommendations: Generate actionable insights and recommendations

â€¢	User-Friendly Interface: Modern web interface built with Streamlit


## Technology Stack ðŸ› ï¸

â€¢	Backend: Python

â€¢	AI Model: Ollama (LLaMA 3.2)

â€¢	Framework: Swarm Framework for AI agent coordination

â€¢	Frontend: Streamlit

â€¢	File Processing: PDF processing capabilities

â€¢	Logging: Custom logging system


## Prerequisites ðŸ“‹

â€¢	Python 3.8+

â€¢	Ollama 

â€¢	Required Python packages (listed in requirements.txt)

## Installation ðŸš€

1. Clone the repository:

```bash
git clone https://github.com/yourusername/ai-recruiter-agency.git
cd ai-recruiter-agency
```
2. Create and activate a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages:

```bash
pip install -r requirements.txt
```

4. Set up Ollama:

```bash
# Install Ollama following the official documentation
# Pull the LLaMA 3.2 model
ollama pull llama2:3.2
```
## Project Structure ðŸ“

ai-recruiter-agency/

â”œâ”€â”€ app.py                  # Main Streamlit application

â”œâ”€â”€ agents/

â”‚   â””â”€â”€ orchestrator.py     # AI agent orchestration

â”œâ”€â”€ utils/

â”‚   â”œâ”€â”€ logger.py          # Logging configuration

â”‚   â””â”€â”€ exceptions.py      # Custom exceptions

â”œâ”€â”€ uploads/               # Temporary storage for uploads

â”œâ”€â”€ results/              # Analysis results storage

â””â”€â”€ requirements.txt      # Project dependencies
## Usage ðŸ’¡

1. Start the application:

```bash
streamlit run app.py
```

2. Access the web interface at  http://localhost:8501
3. Upload a PDF resume and wait for the analysis results
4. View the results across four categories:
â€¢	Analysis

â€¢	Job Matches

â€¢	Screening

â€¢	Recommendations



## Configuration âš™ï¸

Create a .env file in the project root:

env
```bash
OLLAMA_API_URL=http://localhost:11434
LOG_LEVEL=INFO
```
## Deployment ðŸŒ

### Local Deployment

1.	Ensure all prerequisites are installed
2.	Follow the installation steps
3.	Run the application using Streamlit

### Docker Deployment

1. Build the Docker image:

```bash
docker build -t ai-recruiter-agency .
```

2. Run the container:

```bash
docker run -p 8501:8501 ai-recruiter-agency
```

### Cloud Deployment
The application can be deployed to various cloud platforms:

â€¢	Streamlit Cloud: Direct deployment with GitHub repository

â€¢	Heroku: Using the Procfile included in the repository

â€¢	AWS/GCP: Using container services (ECS/GKE)



## API Documentation ðŸ“š

The Orchestrator Agent provides the following main methods:
python
```bash
async def process_application(resume_data: dict) -> dict:
    """
    Process a resume through the AI recruitment pipeline
    
    Parameters:
    resume_data (dict): Dictionary containing resume file path and metadata
    
    Returns:
        dict: Analysis results including skills, matches, and recommendations
    """
```
## Badges

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![GPLv3 License](https://img.shields.io/badge/License-GPL%20v3-yellow.svg)](https://opensource.org/licenses/)
[![AGPL License](https://img.shields.io/badge/license-AGPL-blue.svg)](http://www.gnu.org/licenses/agpl-3.0)


## License

[MIT](https://choosealicense.com/licenses/mit/)

